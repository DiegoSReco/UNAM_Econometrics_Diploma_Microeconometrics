---
title: "Diplomado Econometr√≠a Modulo IV:<br> Modelos de Respuesta Binaria"
subtitle: "Universidad Nacional Aut√≥noma de M√©xico (UNAM)<br>Facultad de Econom√≠a"
author: "Mtro. Diego S√°nchez Rojas"
editor: visual
format:
  revealjs:
    center-subtitle-slide: false
    slide-number: c/t
    self-contained: true
    slide-level: 4
    incremental: true
---

#### Secci√≥n 1: Modelos de respuesta binaria (Contenido)

**I. Modelo de probabilidad lineal**

**II. Modelos Probit y Logit**

#### Secci√≥n 1: Modelos de respuesta binaria {.smaller}

-   Los modelos de respuesta binaria son fundamentales cuando la variable de inter√©s es dicot√≥mica (0 o 1).

-   Econom√≠a Laboral:

    -   Participar en la fuerza laboral (1) vs no participar (0)
    -   Formal (1) vs Informal (0)
    -   Sindicalizarse (1) vs no sindicalizarse (0)

-   Econom√≠a de la salud:

    -   Actividad f√≠sica (1) vs no actividad f√≠sica (0)
    -   Seguro m√©dico p√∫blico (1) vs privado (0)

-   Industria financiera

    -   Aprobar un cr√©dito (1) vs no aprobar (0)

#### Secci√≥n 1: Modelos de respuesta binaria {.smaller}

Formalmente $y$ ser√° un variable aletoria que tomar√° dos √∫nicos valores :

$$
\text{y} = \begin{cases}
0 ~if~ no \\
1 ~if~ yes
\end{cases}
$$

-   El objetivo es modelar la **probabilidad de respuesta**:

$$p(x) = P(y = 1 \mid x)$$ - Es decir, queremos predecir la **probabilidad de que ocurra un evento**, dadas ciertas caracter√≠sticas $x$

(Wooldridge, 2009)

#### Secci√≥n 1: Modelos de respuesta binaria {.smaller}

La probabilidad de respuesta es la **probabilidad condicional** de que la variable binaria tome el valor 1, dadas los regresores $x_1, x_2, ..., x_k$

$$p(x) = P(y = 1 \mid x_1, x_2, ..., x_k)$$

-   Representa c√≥mo cambian las **probabilidades esperadas de √©xito** a medida que cambian los valores de las variables explicativas

Podemos estimarlo como un modelo de regresi√≥n lineal donde:

$$p(y=1|x) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k$$ (m.1)

-   m.1 ser√° la especificaci√≥n del Modelo de Probabilidad Lineal (MPL o $LPM$)

(Wooldridge, 2009)

#### Secci√≥n 1: Modelos de respuesta binaria {.smaller}

Sea $p(x) = P(y = 1 \mid x)$ y asumiendo que $x_1$ no tiene relaci√≥n con otra variable explicativa, el par√°metro $\beta_j=\beta_1$ representa:

$$
\beta_1 = \frac{\partial P(y = 1 \mid x)}{\partial x_1}
$$

-   $\beta_1$ ser√° el cambio en la probabilidad de √©xito dado el cambio en una unidad de $x_1$, manteniendo las dem√°s constantes.

-   Si $x_1$ es una variable **binaria**, $\beta_1$ ser√° ** la diferencia en la probabilidad** de √©xito cuando:

    $x_j = 1 \quad \text{vs} \quad x_j = 0$

(Wooldridge, 2009)

#### Secci√≥n 1: Modelos de respuesta binaria (Transformaciones funcionales) {.smaller}

**Transformaciones funcionales**

Podemos incluir funciones como $x_j^2$, $\log(x_j)$, etc lo cual **no cambia la interpretaci√≥n general**:

-   $\beta_j$ mide el efecto parcial sobre la **probabilidad predicha**, no sobre el valor esperado como en regresiones cl√°sicas.


Por lo tanto, en el **MPL un cambio unitario en** $x_j$ implica un cambio en la $P(y = 1 \mid x)$.

(Wooldridge, 2009)

#### Secci√≥n 1: Modelos de respuesta binaria (Desventajas) {.smaller}

-   El MPL no realizar√° una descripci√≥n correcta de la probabilidad de respuesta a menos que el rango de los valores de $\mathbf{x}$ est√©n muy restringidos.

-   La probabilidad predicha se modela como una **funci√≥n lineal**:

$$
 \hat P(y = 1 \mid \mathbf{x}) = \hat\beta_0 + \hat\beta_1 x_1 + \dots + \hat\beta_k x_k
$$

-   Pero una **funci√≥n lineal no est√° acotada**: puede tomar cualquier valor real

-   Como resultado, es com√∫n que el modelo haga predicciones de valores fuera del intervalo $[0, 1]$

$$\frac{\partial P(y = 1 \mid \mathbf{x})}{\partial x_j} = \beta_j$$

-   Cada unidad adicional de $x_j$ **siempre cambia la probabilidad en la misma cantidad**, sin importar el valor de $x_j$

#### Secci√≥n 1: Modelos de respuesta binaria (Funcionalidad) {.smaller}

¬øEn qu√© contexto es funcional?

-   **Efecto marginal lineal**: La probabilidad no puede estar relacionada de forma lineal con las variables independientes para todos los valores posibles.

-   MPL no representa exactamente c√≥mo cambia la probabilidad de que ocurra un evento (por ejemplo, conseguir trabajo, aprobar un cr√©dito), ya que la funci√≥n que lo describe no puede ser lineal en todo el dominio de las variables independientes.

-   Puede ser √∫til como una aproximaci√≥n razonable en el rango de valores donde se encuentran la mayor√≠a de las observaciones. (**Aproximaci√≥n local**)

-   En la pr√°ctica aplicada, cuando los valores de los variables explicativas est√°n moderadamente distribuidos (por ejemplo, entre 5 y 15 a√±os de educaci√≥n, o entre 20 y 60 a√±os de edad), la **relaci√≥n lineal** puede aproximar bien a la verdadera probabilidad.

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo b√°sico) {.smaller}

Tenemos $n = 10$ observaciones con:

-   $y_i$: variable binaria (0 √≥ 1)

-   $x_i$: variable continua

$$
\begin{array}{c|cccccccccc}
i & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\hline
y_i & 0 & 0 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 \\
x_i & 2 & 3 & 5 & 4 & 7 & 8 & 9 & 6 & 10 & 11 \\
\end{array}
$$

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo b√°sico) {.smaller}

Planteamos el MPL de probabilidad lineal a estimar: $$P(y_i = 1|x_i) = \beta_0 + \beta_1 x_i + \varepsilon_i$$

En el MPL se utiliza OLS para estimar $\beta_0$ y $\beta_1$ por tanto:

$$
\hat{\beta}_{OLS} = (X'X)^{-1}X'Y
$$

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo b√°sico) {.smaller}

**Matriz de dise√±o** $\mathbf{X}$ y el vector de la variable $Y$:

$$\mathbf{X} = \begin{pmatrix}
1 & 2 \\
1 & 3 \\
1 & 5 \\
1 & 4 \\
1 & 7 \\
1 & 8 \\
1 & 9 \\
1 & 6 \\
1 & 10 \\
1 & 11
\end{pmatrix}_{10 \times 2} \quad
\mathbf{Y} = \begin{pmatrix}
0 \\
0 \\
1 \\
0 \\
1 \\
1 \\
1 \\
0 \\
1 \\
1
\end{pmatrix}_{10 \times 1}$$

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo b√°sico) {.smaller}

Obtenemos $\mathbf{X}'\mathbf{X}$:

$$
\mathbf{X}'\mathbf{X} = \begin{pmatrix}
\sum_{i=1}^{10} 1 & \sum_{i=1}^{10} x_i \\
\sum_{i=1}^{10} x_i & \sum_{i=1}^{10} x_i^2
\end{pmatrix} = \begin{pmatrix}
10 & 65 \\
65 & 505
\end{pmatrix}
$$

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo b√°sico) {.smaller}

-   Calculamos la inversa $(\mathbf{X}'\mathbf{X})^{-1}$:

$$
(\mathbf{X}^\top \mathbf{X})^{-1} = \frac{1}{825}
\begin{bmatrix}
505 & -65 \\
-65 & 10
\end{bmatrix}
$$

-   y $\mathbf{X}'\mathbf{y}$ :

$$
\mathbf{X}'\mathbf{y} = \begin{pmatrix}
\sum_{i=1}^{10} y_i \\
\sum_{i=1}^{10} x_i y_i
\end{pmatrix} = \begin{pmatrix}
6 \\
50
\end{pmatrix}
$$

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo b√°sico) {.smaller}

Obtenemos $\boldsymbol{\hat{\beta}}$: $$
\hat{\boldsymbol\beta} = \frac{1}{825}
\begin{bmatrix}
505 & -65 \\
-65 & 10
\end{bmatrix}
\begin{bmatrix}
6 \\
50
\end{bmatrix}
= \frac{1}{825}
\begin{bmatrix}
-220 \\
110
\end{bmatrix}
= \begin{bmatrix}
-0.2667 \\
0.1333
\end{bmatrix}
$$

-   Modelo estimado:

$\hat{P}(y_i = 1|x_i) = -0.2667 + 0.1333 x_i$

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo b√°sico (Comprobaci√≥n en R)) {.smaller}

-   En R podremos realizar de forma "manual" o utilizando la funcion lm():

```{r}
#| warning: false
#| echo: true
#| label: toyexamp

# Variables
x <- c(2, 3, 5, 4, 7, 8, 9, 6, 10, 11)
y <- c(0, 0, 1, 0, 1, 1, 1, 0, 1, 1)

# C√°lculo matricial
X <- cbind(1, x)
beta_hat <- solve(t(X) %*% X) %*% t(X) %*% y
print(beta_hat)

# Modelo lineal utilizando formula lm
modelo_lpm <- lm(y ~ x)
print( modelo_lpm)
```

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo b√°sico) {.smaller}

-   **Predicciones del MPL**

| $x_i$ | $\hat{y}_i = -0.2667 + 0.1333 \cdot x_i$ | Valor   |
|-------|------------------------------------------|---------|
| 2     | $-0.2667 + 0.1333 \cdot 2 = -0.0001$     | ‚ùå \< 0 |
| 3     | $0.1333$                                 | ‚úÖ      |
| 4     | $0.2666$                                 | ‚úÖ      |
| 5     | $0.3999$                                 | ‚úÖ      |
| 6     | $0.5332$                                 | ‚úÖ      |
| 7     | $0.6665$                                 | ‚úÖ      |
| 8     | $0.7998$                                 | ‚úÖ      |
| 9     | $0.9331$                                 | ‚úÖ      |
| 10    | $1.0663$                                 | ‚ùå \> 1 |
| 11    | $1.1996$                                 | ‚ùå \> 1 |

-   Limitaci√≥n del MPL

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo) {.smaller}

Ejemplo de Wooldridge,2009:

-   Utilizamos datos de *Wooldridge Source: T.A. Mroz (1987), ‚ÄúThe Sensitivity of an Empirical Model of Married Women‚Äôs Hours of Work to Economic and Statistical Assumptions‚Äù*

-   Modelo de probabilidad lineal sobre la decisi√≥n de las mujeres de trabajar fuera del hogar:

$$inlf_i = \beta_0 + \beta_1 \cdot age_i + \beta_2 \cdot educ_i + \beta_3 \cdot exper_i + \beta_4 \cdot nwifeinc_i + \beta_5 \cdot kidslt6_i + \beta_6 \cdot kidsge6_i + u_i  $$ $$~~~~~ (M.2)$$

#### Secci√≥n 1: Modelos de respuesta binaria (Descripci√≥n de variables) {.smaller}

Donde:

-   $inlf_i$: 1 si la mujer trabaj√≥ fuera del hogar (horas \> 0), 0 si no
-   $age$: Edad de la mujer (en a√±os)
-   $exper$ y $exper^2$: A√±os de experiencia laboral potencial
-   $educ$: A√±os de educaci√≥n completados
-   $nwifeinc_i$: Ingresodel hogar no generado por la esposa (en miles de d√≥lares anuales)
-   $kidslt6_i$: n√∫mero de hijos menores de 6 a√±os\
-   $kidsge6_i$: n√∫mero de hijos entre 6 y 18 a√±os

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo en R) {.smaller}

-   En R el conjunto de datos `MROZ.RAW` lo podemos encontrar en la librer√≠a **wooldridge**

-   https://justinmshea.github.io/wooldridge/reference/mroz.html

```{r}
#| warning: false
#| echo: true
#| label: data

#Librerias
if (!require(pacman, quietly = TRUE)) {install.packages('pacman')}
library(pacman)
p_load( 'wooldridge','tidyverse','modelsummary','skimr', 'dplyr', 'gtsummary')

#Cargamos datos 
data("mroz")
#Descripci√≥n
skim(mroz)

```

#### Secci√≥n 1: Modelos de respuesta binaria (Visualizaci√≥n Y) {.smaller}

::: columns
::: {.column width="60%"}
-   La muestra es de 753 observaciones
-   Variable objetivo: ¬øCu√°ntas mujeres est√°n ocupadas?

```{r}
#| echo: true
#| eval: false
#| label: descriptivos


df_mroz <- mroz  |> 
            mutate(inlf_1= factor(inlf, labels = c("No trabaja", "Trabaja"))) 
  
ggplot(df_mroz, aes(x = factor(inlf_1), fill = factor(inlf_1))) +
  geom_bar(alpha = 0.8) +
 geom_text(stat = 'count', 
            aes(label = paste0(after_stat(count), "\n(", 
                              round(after_stat(count)/sum(after_stat(count))*100, 1), "%)")), 
            vjust = 1.5, size = 4) +

  labs(
    title = "Estado laboral de las mujeres en la muestra",
    x = "Estado laboral", 
    y = "N√∫mero de mujeres",
    caption = "inlf_1: 1 = trabaja fuera del hogar, 0 = no trabaja"
  ) +
  theme_minimal() +
  theme(legend.position = "none")  


```
:::

::: {.column width="40%"}
```{r}
#| warning: false
#| echo: false
#| label: descriptivos_y1
#| fig-width: 16
#| fig-height: 14

df_mroz <- mroz  |> 
            mutate(inlf_1= factor(inlf, labels = c("No trabaja", "Trabaja"))) 
  
ggplot(df_mroz, aes(x = factor(inlf_1), fill = factor(inlf_1))) +
  geom_bar(alpha = 0.8) +
 geom_text(stat = 'count', 
            aes(label = paste0(after_stat(count), "\n(", 
                              round(after_stat(count)/sum(after_stat(count))*100, 1), "%)")), 
            vjust = 1.5, size = 7) +

  labs(
    title = "Estado laboral de las mujeres en la muestra",
    x = "Estado laboral", 
    y = "N√∫mero de mujeres",
    caption = "inlf_1: 1 = trabaja fuera del hogar, 0 = no trabaja"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        text = element_text(size = 24)) 


```
:::
:::

#### Secci√≥n 1: Modelos de respuesta binaria (Visualizaci√≥n de Xs) {.smaller}

::: columns
::: {.column width="40%"}
-   ¬øC√≥mo se distribuyen los regresores por los valores de la variable objetivo?

```{r}
#| echo: true
#| eval: false
#| label: descrip_x

df_boxplots <- df_mroz |>  
               select(inlf_1, nwifeinc, age, educ, exper, kidslt6, kidsge6) |> 
               pivot_longer(cols = -inlf_1, names_to = "variable", values_to = "valor") |> 
               mutate(inlf_1 = factor(inlf_1, labels = c("No trabaja", "Trabaja")))

#Plot
ggplot(df_boxplots,
       aes(x = inlf_1, y = valor, fill = inlf_1)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~variable, scales = "free_y", ncol = 3) +
  labs(title = "Distribuci√≥n de variables por estado laboral",
       x = "Estado laboral",
       y = "Valor") +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1))
```
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| label: descrip_x2
#| fig-width: 12
#| fig-height: 12

df_boxplots <- df_mroz |>  
               select(inlf_1, nwifeinc, age, educ, exper, kidslt6, kidsge6) |> 
               pivot_longer(cols = -inlf_1, names_to = "variable", values_to = "valor") |> 
               mutate(inlf_1 = factor(inlf_1, labels = c("No trabaja", "Trabaja")))

#Plot
ggplot(df_boxplots,
       aes(x = inlf_1, y = valor, fill = inlf_1)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~variable, scales = "free_y", ncol = 3) +
  labs(title = "Distribuci√≥n de variables por estado laboral",
       x = "Estado laboral",
       y = "Valor") +
  theme_minimal() +
  theme(legend.position = "none",
        text = element_text(size = 22),         
        axis.text.x = element_text(angle = 45, hjust = 1))
```
:::
:::

#### Secci√≥n 1: Modelos de respuesta binaria (Visualizaci√≥n de Ingreso) {.smaller}

-   ¬øC√≥mo se distribuye el ingreso no generado por la esposa por la condici√≥n de empleo?

```{r}
#| warning: false
#| echo: true
#| label: descriptivos3

ggplot(df_mroz, aes(x = nwifeinc, fill = factor(inlf_1, labels = c("No trabaja", "Trabaja")))) +
  geom_density(alpha = 0.6) +
  labs(
    title = "Distribuci√≥n del ingreso no generado por la esposa",
    subtitle = "Por estado laboral",
    x = "Ingreso no-esposa (miles de d√≥lares)",
    y = "Densidad",
    fill = "Estado laboral"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")


```

#### Secci√≥n 1: Modelos de respuesta binaria (Prueba de significancia) {.smaller}

-   Usamos un prueba T (t_test) para comprobar que la diferencia sea significativa

-   Interpretaci√≥n:

    -   ‚úÖ p \< 0.05 (espec√≠ficamente p = 0.001226)
    -   ‚úÖ Hay una diferencia estad√≠sticamente significativa

-   Existe una diferencia significativa en el ingreso no generado por la esposa (nwifeinc) entre:

```{r}
#| warning: false
#| echo: true
#| label: descriptivos4

#prueba T
t.test(nwifeinc ~ inlf_1, data = df_mroz, var.equal = TRUE)  


```


#### Secci√≥n 1: Modelos de respuesta binaria (MPL) {.smaller}

-   Estimaci√≥n en R de MPL para modelo especificado (M.2)

```{r}
#| warning: false
#| echo: true
#| label: MPI

modelo_mpl <- lm(inlf ~ age + educ + exper + I(exper^2) + nwifeinc + kidslt6 + kidsge6, data = mroz)


summary(modelo_mpl)

```


#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n) {.smaller}

-   Cada $\beta_j$ representa el **efecto marginal** de $x_j$ sobre la probabilidad de que $y = 1$.

-   Si $\beta = 0.04$ se muliplica por 100 para decir que un aumento en una unidad de $x_i$ tendr√° un efecto $0.04$ x $100$ pp

| Variable   | Coef.   | Error Est. | Interpretaci√≥n                                                                                                          |
|---------|---------|---------|---------------------------------------------|
| `exper`    | 0.039   | (0.006)    | Cada a√±o adicional de experiencia laboral **aumenta la probabilidad** de trabajar en **3.9 puntos porcentuales**.       |
| `exper^2`  | -0.0006 | (0.000)    | El efecto de la experiencia **disminuye con el tiempo**: rendimientos decrecientes.                                     |
| `nwifeinc` | -0.0034 | (0.001)    | Cada 10 mil d√≥lares extra del ingreso del esposo **reduce la probabilidad** de trabajar en **0.3 puntos porcentuales**. |
| `kidslt6`  | -0.262  | (0.034)    | Tener un hijo menor de 6 a√±os **reduce la probabilidad** de trabajar en **26.2 puntos porcentuales**.                   |
| `kidsge6`  | 0.013   | (0.013)    | Tener hijos entre 6 y 18 a√±os **incrementa** la probabilidad (no significativo estad√≠sticamente).                       |

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n Experiencia ) {.smaller}

-   Vimos que el efecto de la experiencia disminuye con el tiempo por lo tanto tenemos **rendimiento decrecientes**

-   El efecto marginal **disminuye con la experiencia**.

Es posible calcular el punto nivel de experiencia donde el efecto marginal se vuelve cero:

$$\frac{\partial P(inlf = 1)}{\partial exper} = \beta_1 + 2\beta_2 \cdot exper = 0$$

Por tanto:

$$exper = \frac{\ \beta_1}{2\beta_2} = \frac{0.039}{2(0.001)} = 19.5 $$

-   La probabilidad de participaci√≥n crece con la experiencia hasta los 19.5 a√±os, luego comienza a disminuir.

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n Intercepto) {.smaller}

-   Se estim√≥:

    $$ \hat\beta_0 = 0.586 $$

-   La probabilidad predicha de que una mujer trabaje cuando todas las variables explicativas son cero.

#### Secci√≥n 1: Modelos de respuesta binaria (Prediction range) {.smaller}

-   Al realizar la predicci√≥n de probabilidades del modelo se observa que aproximadamente 4.4% de las predicciones del MPL est√°n fuera del intervalo v√°lido es decir, son menores a 0 o mayores a 1.

```{r}
#| warning: false
#| echo: true
#| label: MPI_range

preds <- predict(modelo_mpl)

out_range <- mean(preds < 0 | preds > 1)

print(out_range*100)

```

#### Secci√≥n 1: Modelos de respuesta binaria (Diagn√≥stico) {.smaller}

Residuos vs. valores ajustados

‚úîÔ∏è Ideal: dispersi√≥n aleatoria alrededor de 0\
‚Üí indica **linealidad** y **homocedasticidad**\
‚ùå Problemas: - Curvas = falla de linealidad\
- Forma de embudo = heterocedasticidad

```{r}
#| warning: false
#| echo: true
#| label: MPI_diag

plot(modelo_mpl, which = 1, main = "Residuos vs Valores ajustados")


```

#### Secci√≥n 1: Modelos de respuesta binaria (Diagn√≥stico) {.smaller}

Gr√°fico Q-Q (cuantil-cuantil)

‚úîÔ∏è Ideal: residuos alineados en diagonal\
‚Üí indica **normalidad de los errores**

‚ùå Problemas: - Forma de ‚ÄúS‚Äù - colas ligeras\
- Curvatura - asimetr√≠a\
- Puntos extremos - outliers o colas pesadas

```{r}
#| warning: false
#| echo: true
#| label: MPI_diag1

plot(modelo_mpl, which = 2, main = "Gr√°fico Q-Q de los residuos")

```

#### Secci√≥n 1: Modelos de respuesta binaria (Diagn√≥stico) {.smaller}

Colinealidad ‚Äì VIF (Variance Inflation Factor)

‚úîÔ∏è Ideal: VIF \< 5 (o 10 como l√≠mite laxo)\
‚Üí no hay **multicolinealidad severa**\
‚ùå Problemas: - VIF altos = variables muy correlacionadas

Soluciones: - Elimina variables redundantes

```{r}
#| warning: false
#| echo: true
#| label: MPI_diag2

p_load('car')

vif( modelo_mpl)

```

#### Secci√≥n 1: Modelos de respuesta binaria (Regresor ) {.smaller}

-   ¬øQu√© sucede cuando tengo una variable explicativa binaria?

```{r}
#| warning: false
#| echo: true
#| label: MPI_bin

modelo_mpl_bi <- lm(inlf ~ age + educ + exper + I(exper^2) + nwifeinc + kidslt6 + kidsge6 + city, data = mroz)


summary(modelo_mpl_bi)

```

-   El coeficiente representa la diferencia en la probabilidad promedio entre las dos categor√≠as.

-   Interpretaci√≥n: Las mujeres que viven en √°reas metropolitanas tienen una probabilidad de participar en la fuerza laboral que es 1.25 puntos porcentuales menor comparado con las mujeres que no viven en √°reas metropolitanas, manteniendo todas las dem√°s variables constantes.

#### Secci√≥n 1: Modelos de respuesta binaria (Conclusi√≥n) {.smaller}

-   El **Modelo de Probabilidad Lineal (MPL)** es f√°cil de estimar con OLS, pero tiene fallas importantes:

    -   Puede predecir valores fuera del intervalo (\[0, 1\])
    -   Supone **varianza constante** (homocedasticidad), lo cual no se cumple con variable binaria
    -   No modela bien la relaci√≥n no lineal entre $x_k$ y la probabilidad

-   Alternativas

    -   Utilizar modelos que utilicen una forma funcional $F(\cdot)$ que asegure que la probabilidad predicha est√© entre 0 y 1.
    -   **Logit y Probit**

#### Secci√≥n 1: Modelos de respuesta binaria (Modelo √≠ndice) {.smaller}

-   Dado que el MPL lineal tiene la limitaci√≥n de que la probabilidad de respuesta no siempre puede estar en 0 y 1 para todas las $\mathbf{x_i}$ utilizaremos el **modelo √≠ndice** representado como:

$$P(y = 1 \mid \mathbf{x}) = G(\mathbf{x}\boldsymbol{\beta}) \equiv p(\mathbf{x}) ~~~~(m.√≠ndice)$$

-   La probabilidad de respuesta depende de $\mathbf{x}$ **solo** a trav√©s del √≠ndice:

$$\mathbf{x}\boldsymbol{\beta} = \beta_1+ \beta_2x_2 + \beta_kx_k$$

#### Secci√≥n 1: Modelos de respuesta binaria (Modelo √≠ndice) {.smaller}

-   La funci√≥n $G(\cdot)$ convierte ese √≠ndice ($\mathbf{x}\boldsymbol{\beta}$) en una probabilidad.

-   En la mayor√≠a de las aplicaciones $G$ es una funci√≥n de distribuci√≥n acumuladada (cdf)

-   $0 < G(z) < 1 \quad \text{para todo } z \in \mathbb{R}$

-   La funci√≥n $G(z)$ **transforma** la combinaci√≥n lineal $\mathbf{x}\boldsymbol{\beta}$ en una **probabilidad v√°lida**.

#### Secci√≥n 1: Modelos de respuesta binaria (Modelo √≠ndice) {.smaller}

-   Dado un comportamiento binario observado $y \in \{0,1\}$, suponemos que hay una variable continua no observada $y^*$:

$$
y^* = \mathbf{x} \boldsymbol{\beta} + e, \quad y = 1 \quad si \quad y^*>0
$$

-   $y^*$ ser√° una variable latente que representa la utilidad neta, deseo, propensi√≥n o decisi√≥n interna.

-   $e$ error es **continuamente distribuido**, independiente de $\mathbf{x}$ y tiene **distribuci√≥n sim√©trica respecto a 0** 


#### Secci√≥n 1: Modelos de respuesta binaria (Modelo √≠ndice) {.smaller}

-   Si se cumple los supuestos de $e$ podemor derivar la probabilidad de respuesta como:

$$\mathbb{P}(y = 1 \mid \mathbf{x}) = \mathbb{P}(y^* > 0|\mathbf{x} )=\mathbb{P}( \mathbf{x}\boldsymbol{\beta} + e > 0|\mathbf{x})=(e > -\mathbf{x}\boldsymbol{\beta}|\mathbf{x})= \mathbb{P}(e > -\mathbf{x}\boldsymbol{\beta}|\mathbf{x})=
$$ - Como $e$ es una variable aleatoria con una distribuci√≥n acumulada $G(.)$ y por el supuesto de simetr√≠a respecto a 0 del error $e$:

$$1 - G(-\mathbf{x}\boldsymbol{\beta}) = G(\mathbf{x}\boldsymbol{\beta})$$ - La probabilidad de que $G$ tome un valor positivo $\mathbf{x}\boldsymbol{\beta}$ es igual a que $G$ tome un valor negativo $-\mathbf{x}\boldsymbol{\beta}$

#### Secci√≥n 1: Modelos de respuesta binaria (Modelo √≠ndice) {.smaller}

Por tanto tenemos la formula general del modelo √≠ndice:

$$\mathbb{P}(y = 1 \mid \mathbf{x})  = G(\mathbf{x}\boldsymbol{\beta})$$

Donde G es una funci√≥n acumulada sim√©trica y en casos particulares:

-   Probit:

$$G(z) = \Phi(z) = \int_{-\infty}^{z} \phi(v) \, dt
\quad $$

-   Logit:

$$
G(z)= \Lambda(z) = \frac{e^z}{1 + e^z} = \frac{1}{1 + e^{-z}}
$$

#### Secci√≥n 1: Modelos de respuesta binaria (Probit) {.smaller}

-   El modelo **Probit** es un caso particular\
    $$P(y = 1 \mid \mathbf{x}) = \Phi(z) \quad (m.probit)$$

Donde la CDF:

$$\Phi(z) = \int_{-\infty}^{z} \phi(v) \, dt
\quad $$

-   y su densidad normal est√°ndar:

$$\phi(v) = \frac{1}{\sqrt{2\pi}} e^{-v^2/2}$$

#### Secci√≥n 1: Modelos de respuesta binaria (Probit:Estimaci√≥n) {.smaller}

**¬øC√≥mo se estima el modelo Probit?**

-   M√°xima verosimilitud condicional (*CMLE*)

Partimos de:

$$y_i^* = \mathbf{x}_i \boldsymbol{\beta} + e_i, \quad e_i \sim \mathcal{N}(0,1)$$

-   Dado que la variable $y_i$ toma dos valores:

$$\mathbb{P}(y_i = 1 \mid \mathbf{x}_i) =  \Phi(\mathbf{x}_i \boldsymbol{\beta})$$

$$\mathbb{P}(y_i = 0 \mid \mathbf{x}_i) = 1 - \Phi(\mathbf{x}_i \boldsymbol{\beta})$$

#### Secci√≥n 1: Modelos de respuesta binaria (Probit:Estimaci√≥n) {.smaller}

-   Asumimos que contamos con $N$ observaciones independientes e id√©nticamente distribuidas $(i.i.d)$

-   y dada la funci√≥n de probabilidad de $y_i$ dado $\mathbf{x}_i$ podemos escribirla como:

$$ f(y|\mathbf{x}_i;\boldsymbol{\beta}) =  \left[\underbrace{\Phi(\mathbf{x}_i \boldsymbol{\beta}}_{P(y_i=1|x_i)})\right]^{y_i} \left[\underbrace{1 - \Phi(\mathbf{x}_i \boldsymbol{\beta})}_{P(y_i=0|x_i)} \right]^{1 - y_i}$$

#### Secci√≥n 1: Modelos de respuesta binaria (Probit:Estimaci√≥n) {.smaller}

-   El **Paso 1. ser√° obtener la verosimilutd** de la funci√≥n de densidad para un conjunto de datos dados:

$$L(\boldsymbol{\beta}) = \prod_{i=1}^N \left[\Phi(\mathbf{x}_i \boldsymbol{\beta})\right]^{y_i} \left[1 - \Phi(\mathbf{x}_i \boldsymbol{\beta})\right]^{1 - y_i}$$

-   Producto de probabilidades

-   La **verosimilitud** es una funci√≥n que mide qu√© tan probable es observar la muestra de datos que tenemos, dadas ciertas variables explicativas.

-   El objetivo de *CMLE* es encontrar los par√°metros $\beta$ del modelo que hacen m√°s probable (veros√≠mil) haber observado los datos que tenemos.

#### Secci√≥n 1: Modelos de respuesta binaria (Probit:Estimaci√≥n) {.smaller}

-   Paso 2: Con el fin de simplificar matem√°tica y computacionalmente la estimaci√≥n obtenemos la funci√≥n **log-verosimilitud** $\ell(\boldsymbol{\beta})$:

-   $\ell(\boldsymbol{\beta}) = log(L(\boldsymbol{\beta}))$

$$\ell(\boldsymbol{\beta}) = \sum_{i=1}^N \left\{ y_i \log \left[\Phi(\mathbf{x}_i \boldsymbol{\beta}) \right] + (1 - y_i) \log \left[1 - \Phi(\mathbf{x}_i \boldsymbol{\beta}) \right] \right\}$$

#### Secci√≥n 1: Modelos de respuesta binaria (Probit:Estimaci√≥n) {.smaller}

-   Paso 3: Estimaci√≥n de $\boldsymbol{\beta}$

$$\hat{\boldsymbol{\beta}} = \arg \max_{\boldsymbol{\beta}} \ell(\boldsymbol{\beta})$$

-   No hay soluci√≥n anal√≠tica: se debe resolver por m√©todos de optimizaci√≥n num√©rica

-   Newton-Raphson ,BFGS (Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno), Fisher scoring

#### Secci√≥n 1: Modelos de respuesta binaria (Probit:Estimaci√≥n) {.smaller}

-   Todos buscan encontrar el valor de $\boldsymbol{\beta}$ que **maximiza la log-verosimilitud**.

-   Resuelven la **condici√≥n de primer orden**:

| M√©todo         | Usa Hessiana exacta | Usa gradiente | Aprox. Hessiana   | Estable y eficiente          |
|--------------|--------------|--------------|--------------|-----------------|
| Newton-Raphson | ‚úÖ S√≠               | ‚úÖ S√≠         | ‚ùå No             | ‚ö†Ô∏è Solo si Hessiana es f√°cil |
| BFGS           | ‚ùå No               | ‚úÖ S√≠         | ‚úÖ S√≠             | ‚úÖ Muy usado                 |
| Fisher Scoring | ‚ùå Usa esperanza    | ‚úÖ S√≠         | ‚úÖ S√≠ (esperanza) | ‚úÖ Muy usado en GLM          |

#### Secci√≥n 1: Modelos de respuesta binaria (Logit) {.smaller}

-   Dado que $e_i \sim \text{Log√≠stica}(0,1)$, se tiene:

-   La forma particular del modelo indice:

$$
\mathbb{P}(y_i = 1 \mid \mathbf{x}_i) = G(z)= \Lambda(\mathbf{x}_i \boldsymbol{\beta}) = \frac{1}{1 + e^{-\mathbf{x}_i \boldsymbol{\beta}}} = \frac{e^{\mathbf{x}_i \boldsymbol{\beta}}}{1 + e^{\mathbf{x}_i \boldsymbol{\beta}}}
$$

$$
\mathbb{P}(y_i = 0 \mid \mathbf{x}_i) = 1 - \Lambda(\mathbf{x}_i \boldsymbol{\beta}) = \frac{e^{-\mathbf{x}_i \boldsymbol{\beta}}}{1 + e^{-\mathbf{x}_i \boldsymbol{\beta}}}
$$

#### Secci√≥n 1: Modelos de respuesta binaria (Logit) {.smaller}

-   Paso 1: Obtener verosimilutd de la funci√≥n de densidad

$f(y|\mathbf{x}_i;\boldsymbol{\beta})$ :

$$L(\boldsymbol{\beta}) = \prod_{i=1}^N \left[ \Lambda(\mathbf{x}_i \boldsymbol{\beta}) \right]^{y_i} \left[ 1 - \Lambda(\mathbf{x}_i \boldsymbol{\beta}) \right]^{1 - y_i}$$

#### Secci√≥n 1: Modelos de respuesta binaria (Logit) {.smaller}

-   Paso 2: obtenemos la funci√≥n log-verosimilitud $\ell(\boldsymbol{\beta})$

$$\ell(\boldsymbol{\beta}) = \sum_{i=1}^N \left[ 
y_i \log \Lambda(\mathbf{x}_i \boldsymbol{\beta}) + (1 - y_i) \log \left( 1 - \Lambda(\mathbf{x}_i \boldsymbol{\beta}) \right)
\right]$$

#### Secci√≥n 1: Modelos de respuesta binaria (Logit) {.smaller}

-   Reemplazamos en la funci√≥n $\Lambda(z)$ en la $\ell(\boldsymbol{\beta})$:

$$\Lambda(z) = \frac{e^z}{1 + e^z}, \quad \log \Lambda(z) = z - \log(1 + e^z)$$

Por tanto:

$$\ell(\boldsymbol{\beta}) = \sum_{i=1}^N \left[
y_i \cdot \mathbf{x}_i \boldsymbol{\beta} - \log(1 + e^{\mathbf{x}_i \boldsymbol{\beta}})
\right]$$

#### Secci√≥n 1: Modelos de respuesta binaria (Logit) {.smaller}

-   Es estimdor se encuentra solucionando la:

$$\hat{\boldsymbol{\beta}} = \arg \max_{\boldsymbol{\beta}} \ell(\boldsymbol{\beta})$$

-   Para encontrar m√°ximo encontramos la ecuaci√≥n de primer orden

#### Secci√≥n 1: Modelos de respuesta binaria (Logit) {.smaller}

-   Encontramos el gradiente de $\ell(\boldsymbol{\beta})$ respecto a $\boldsymbol{\beta}$:

$$
\frac{\partial \ell(\boldsymbol{\beta})}{\partial \boldsymbol{\beta}} =
\sum_{i=1}^N \left[
y_i - \Lambda(\mathbf{x}_i \boldsymbol{\beta})
\right] \cdot \mathbf{x}_i=0
$$

-   Lo cual es un sistema de ecuaciones no lineales y como no tiene soluci√≥n cerrada se usan m√©todos de optimizaci√≥n iterativos.

#### Secci√≥n 1: Modelos de respuesta binaria (Ejemplo) {.smaller}

Estimaremos el M.1 como un modelo probit:

$$\mathbb{P}(inlf_i = 1 \mid \mathbf{x}_i) =\Phi( 
\beta_0 + \beta_1 \cdot age_i + \beta_2 \cdot educ_i + \beta_3 \cdot exper_i + \beta_4 \cdot nwifeinc_i +$$

$$\beta_5 \cdot kidslt6_i + \beta_6 \cdot kidsge6_i)$$

-   Donde $\Phi(\cdot)$ es la **funci√≥n de distribuci√≥n normal est√°ndar acumulada**.

#### Secci√≥n 1: Modelos de respuesta binaria (Probit en R) {.smaller}

-   En R utilizaremos la funi√≥n `glm()` de la paqueter√≠a base `stats` para estimar modelos lineal genralizados:

-   La funci√≥n glm utilizan IRLS (Iteratively Reweighted Least Squares) y es una forma del algoritmo de Fisher Scoring

```{r}
#| warning: false
#| echo: true
#| label: Probit


# Modelo Probit con glm()
modelo_probit <- glm(inlf ~ age + educ + exper + I(exper^2) + nwifeinc + kidslt6 + kidsge6,
                     data = mroz,
                     family = binomial(link = "probit"))                    

# Resumen del modelo
summary(modelo_probit)
```

#### Secci√≥n 1: Modelos de respuesta binaria (Evaluaci√≥n) {.smaller}

¬øC√≥mo evaluar un modelo Probit?

-   Dos medidas de bondad de ajuste: **porcentaje de predicciones correctas y pseudo** $R^2$

**1. Porcentaje de observaciones correctamente clasificadas (Accuracy)**

-   Si $G(\mathbf{x_i }\hat{\mathbf\beta} )>.5$ ser√° 1 y $G(\mathbf{x_i }\hat{\mathbf\beta} )<=.5$ la predicci√≥n ser√° 0

```{r}
#| warning: false
#| echo: true
#| label: Probit1


# Predicci√≥n de probabilidades
p_hat <- predict(modelo_probit, type = "response")

# Clasificaci√≥n binaria con umbral 0.5
y_pred <- ifelse(p_hat > 0.5, 1, 0)

# Variable observada
y_obs <- mroz$inlf

# Accuracy
accuracy <- mean(y_pred == y_obs)
print(paste("Accuracy:", round(accuracy, 4)))
```

#### Secci√≥n 1: Modelos de respuesta binaria (Evaluaci√≥n) {.smaller}

**2. Pseudo R-cuadrado (McFadden)**

-   En modelos lineales: $R^2$ mide la proporci√≥n de varianza explicada.

$$R^2_{\text{McFadden}} = 1 - \frac{\ell(\hat{\boldsymbol{\beta}})}{\ell(\boldsymbol{0})}$$

Donde: - $\ell(\hat{\boldsymbol{\beta}})$: log-verosimilitud del modelo ajustado\
- $\ell(\boldsymbol{0})$: log-verosimilitud del modelo nulo (solo intercepto)

#### Secci√≥n 1: Modelos de respuesta binaria (Evaluaci√≥n) {.smaller}

**2. Pseudo R-cuadrado (McFadden)**

-   Para calcular el pseudo $R^2$ utilizamos la funci√≥n `pR2` de la libreria `pscl`:

```{r}
#| warning: false
#| echo: true
#| label: Probit2

#Instalamos paqueter√≠a
p_load(pscl)


pR2(modelo_probit)["McFadden"]
```

-   Valores entre 0.2 y 0.4 **buen ajuste**
-   No se interpreta igual que el $R^2$ de OLS
-   Solo √∫til para **comparar modelos**

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n) {.smaller}

**¬øLos coeficientes estimados** $\hat\beta$ se interpretan igual en un modelo Probit y un MPL?

-   Los coeficientes de un Probit no se interpretan directamente como el cambio en la probabilidad.

-   Esto se debe a la naturaleza no lineal de la funci√≥n de enlace Probit (la funci√≥n de distribuci√≥n acumulada normal est√°ndar).

**¬øC√≥mo se interpretan?**

Se tiene que calcular el efecto marginal que mide el cambio en la probabilidad al cambiar $x_j$, manteniendo lo dem√°s constante como:

$$\frac{\partial \mathbb{P}(y_i = 1)}{\partial x_{ij}} = \phi(\mathbf{x}_i \boldsymbol{\beta}) \cdot \beta_j$$

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n) {.smaller}

1.  Estimaci√≥n $z_i = \mathbf{x}_i \hat{\boldsymbol{\beta}}$

2.  Evaluar en densidad:

$$\phi(z_i) = \frac{1}{\sqrt{2\pi}} e^{-z_i^2 / 2}$$ 3. Multiplicamos:

$$\phi(z_i) \cdot \hat{\beta}_j$$

#### Secci√≥n 1: Modelos de respuesta binaria (Efectos marginales en R) {.smaller}

¬øC√≥mo estimamos los efectos marginales de un modelos probit en R?

-   Utilizamos el paquete `margins`:

```{r}
#| warning: false
#| echo: true
#| label: Probit3


#Cargamos paqueter√≠a
p_load(margins)

#Calculamos
efectos_marginales <- margins(modelo_probit)

summary(efectos_marginales)
```

#### Secci√≥n 1: Modelos de respuesta binaria (Efectos marginales en R) {.smaller}

-   Interpretaciones efectos marginales del modelo probit

| Variable   | AME     | Interpretaci√≥n                                                                                                                          |
|----------|----------|----------------------------------------------------|
| `age`      | -0.0159 | Un a√±o m√°s de edad **reduce** la probabilidad de trabajar en **1.59 puntos porcentuales**, en promedio.                                 |
| `educ`     | 0.0394  | Un a√±o adicional de educaci√≥n **aumenta** la probabilidad de trabajar en **3.94 puntos porcentuales**.                                  |
| `exper`    | 0.0256  | Un a√±o adicional de experiencia laboral **aumenta** la probabilidad de trabajar en **2.56 puntos porcentuales**.                        |
|            |         |                                                                                                                                         |
| `kidsge6`  | 0.0108  | Tener un hijo mayor de 6 a√±os **aumenta** la probabilidad en **1.08 puntos**, pero **no es estad√≠sticamente significativo** (p = 0.41). |
| `kidslt6`  | -0.2612 | Tener un hijo menor de 6 a√±os **reduce** la probabilidad de trabajar en **26.12 puntos porcentuales**.                                  |
| `nwifeinc` | -0.0036 | Un aumento de \$1,000 en el ingreso del esposo **reduce** la probabilidad de trabajar en **0.36 puntos porcentuales**.                  |

> Todos los efectos est√°n expresados en **puntos porcentuales (pp)** de cambio en la probabilidad de participaci√≥n laboral.

#### Secci√≥n 1: Modelos de respuesta binaria (Logit estimaci√≥n) {.smaller}

-   Al igual que modelo probit utilizaremos la funi√≥n `glm()` de la paqueter√≠a base `stats` para estima el modelo logit.

```{r}
#| warning: false
#| echo: true
#| label: Logit


# Modelo Logit con glm()
modelo_logit <- glm(inlf ~ age + educ + exper + I(exper^2) + 
                      nwifeinc + kidslt6 + kidsge6,
                    data = mroz,
                    family = binomial(link = "logit"))
#summary
summary(modelo_logit)
```

#### Secci√≥n 1: Modelos de respuesta binaria (Evaluaci√≥n Logit) {.smaller}

**¬øC√≥mo evaluar un modelo Logit?**

-   **1. Porcentaje de observaciones correctamente clasificadas (Accuracy)**

-   Si $G(\mathbf{x_i }\hat{\mathbf\beta} )>.5$ ser√° 1 y $G(\mathbf{x_i }\hat{\mathbf\beta} )<=.5$ la predicci√≥n ser√° 0

```{r}
#| warning: false
#| echo: true
#| label: Logit1


# Predicci√≥n de probabilidades
p_hat <- predict(modelo_logit, type = "response")

# Clasificaci√≥n binaria con umbral 0.5
y_pred <- ifelse(p_hat > 0.5, 1, 0)

# Variable observada
y_obs <- mroz$inlf

# Accuracy
accuracy <- mean(y_pred == y_obs)
print(paste("Accuracy:", round(accuracy, 4)))
```

#### Secci√≥n 1: Modelos de respuesta binaria (Evaluaci√≥n Logit) {.smaller}

**2. Pseudo R-cuadrado (McFadden)**

-   Para calcular el pseudo $R^2$ utilizamos la funci√≥n `pR2` de la libreria `pscl`:

```{r}
#| warning: false
#| echo: true
#| label: Logit2

#Instalamos paqueter√≠a
p_load(pscl)


pR2(modelo_logit)["McFadden"]
```

-   Valores entre 0.2 y 0.4 **buen ajuste**
-   No se interpreta igual que el $R^2$ de OLS
-   Solo √∫til para **comparar modelos**

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n Logit) {.smaller}

**¬øLos coeficientes estimados** $\hat\beta$ del modelo Logit se interpretan igual en un modelo de LPM o Probit ?

-   No se pueden interpretar directamente como los $\beta's$ estimados por el MPL ya que los coeficientes $\boldsymbol{\beta}$ estimados representan el **cambio en el logar√≠tmo de los odds** cuando $x_i$ aumenta en una unidad:

$$
\log \left( \frac{\mathbb{P}(y = 1)}{\mathbb{P}(y = 0)} \right) = \mathbf{x}_i \boldsymbol{\beta}
$$

-   Indican cu√°ntas veces es m√°s probable es que ocurra un evento respecto a que no ocurra.

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n Logit) {.smaller}

**¬øC√≥mo se interpretan?**

-   Podemos interpretarlos como **odds ratio**:

-   $e^{\beta_i}$: multiplicador de las **odds** (odds ratio)

$$\text{Cambio % en odds} = \left( e^{\beta} - 1 \right) \times 100$$

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n Logit) {.smaller}

-   Coeficientes del modelo logit:

| Variable   | ( \hat{\beta} ) | Odds Ratio ( e\^{\hat{\beta}} ) | Interpretaci√≥n                                       |
|--------------|-------------:|---------------:|----------------------------|
| Intercepto |           0.425 |                            1.53 | Valor base de los log-odds (no interpretable solo)   |
| age        |          -0.088 |                           0.916 | ‚Üë Edad ‚Üí odds de trabajar ‚Üì 8.4%                     |
| educ       |           0.221 |                           1.247 | ‚Üë 1 a√±o educaci√≥n ‚Üí odds de trabajar ‚Üë 24.7%         |
| exper      |           0.206 |                           1.229 | ‚Üë 1 a√±o experiencia ‚Üí odds ‚Üë 22.9%                   |
| exper¬≤     |        -0.00315 |                          0.9968 | Rendimientos decrecientes de la experiencia          |
| nwifeinc   |          -0.021 |                           0.979 | ‚Üë ingreso esposo ‚Üí odds de trabajar ‚Üì 2.1%           |
| kidslt6    |          -1.443 |                           0.236 | Tener hijos \<6 a√±os ‚Üí odds ‚Üì 76.4%                  |
| kidsge6    |           0.060 |                           1.062 | Tener hijos ‚â•6 a√±os ‚Üí odds ‚Üë 6.2% (no significativo) |

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n Logit) {.smaller}

-   Si queremos interpretarlo como efectos marginales tenemos que:

$$\frac{\partial \mathbb{P}(y = 1)}{\partial x_j} =
\lambda(\mathbf{x} \boldsymbol{\beta}) \cdot \beta_j
\quad \text{donde } \lambda(z) =
\frac{e^{-z}}{(1 + e^{-z})^2}$$

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n Logit) {.smaller}

C√°lculo de efecto marginales para el modelo logit:

```{r}
#| warning: false
#| echo: true
#| label: Logit3

#Calculamos (Average Marginals Effects (AME))
efectos_marginales_logit <- margins(modelo_logit)

summary(efectos_marginales_logit)
```

#### Secci√≥n 1: Modelos de respuesta binaria (Interpretaci√≥n Logit) {.smaller}

-   Interpretaci√≥n por coeficiente

| Variable | AME     | Interpretaci√≥n                                       |
|----------|---------|------------------------------------------------------|
| age      | -0.0157 | ‚Üë edad ‚Üí ‚Üì probabilidad de trabajar (1.57 pp)        |
| educ     | 0.0395  | ‚Üë 1 a√±o educaci√≥n ‚Üí ‚Üë prob. de trabajar (3.95 pp)    |
| exper    | 0.0254  | ‚Üë 1 a√±o experiencia ‚Üí ‚Üë prob. de trabajar (2.54 pp)  |
| kidsge6  | 0.0107  | Tener hijo ‚â•6 a√±os ‚Üí sin efecto claro                |
| kidslt6  | -0.2578 | Tener hijo \<6 a√±os ‚Üí ‚Üì prob. de trabajar (25.8 pp)  |
| nwifeinc | -0.0038 | ‚Üë ingreso del esposo ‚Üí ‚Üì prob. de trabajar (0.38 pp) |

> Todos los efectos est√°n expresados en **puntos porcentuales (pp)** de cambio en la probabilidad de participaci√≥n laboral.

#### Secci√≥n 1: Modelos de respuesta binaria (Conclusiones generales) {.smaller}

*Comparativa general de los modelos de respuesta binarios*

-   **MPL:** r√°pido, coeficientes interpretables directamente como cambios en probabilidad\
    pero puede predecir probabilidades inv√°lidas (\<0 o \>1).

-   **Probit y Logit:** predicen probabilidades en $[0,1]$, manejo natural de la no linealidad.

-   **Logit:** interpreta coeficientes como log-odds, f√°cil convertir a odds ratio.

-   **Probit:** interpreta coeficientes en funci√≥n de error normal latent variable.

#### Secci√≥n 1: Modelos de respuesta binaria (Conclusiones generales) {.smaller}

```{r}

#| echo: true
#| label: plot_final
#| warning: false
#| fig-width: 10
#| fig-height: 8


set.seed(123)
n <- 200
x <- seq(-3, 3, length.out = n)
# Variable latente con funci√≥n log√≠stica
prob_true <- 1 / (1 + exp(- (0.5 + 1.5 * x)))
y <- rbinom(n, 1, prob_true)
data <- data.frame(x = x, y = y)

# Ajustar MPL (modelo de probabilidad lineal)
mpl <- lm(y ~ x, data = data)
data$mpl_fit <- predict(mpl, newdata = data)

# Ajustar Probit
probit <- glm(y ~ x, data = data, family = binomial(link = "probit"))
data$probit_fit <- predict(probit, newdata = data, type = "response")

# Ajustar Logit
logit <- glm(y ~ x, data = data, family = binomial(link = "logit"))
data$logit_fit <- predict(logit, newdata = data, type = "response")

#PLOT
ggplot(data, aes(x = x)) +
  geom_point(aes(y = y), alpha = 0.4, color = "black") +
  geom_line(aes(y = mpl_fit), color = "blue", size = 1, linetype = "dashed") +
  geom_line(aes(y = probit_fit), color = "lightblue", size = 1) +
  geom_line(aes(y = logit_fit), color = "salmon", size = 1) +
  labs(
    y = "Probabilidad estimada / Observada",
    x = "Variable explicativa (x)",
    title = "Comparaci√≥n: MPL, Probit y Logit",
    subtitle = "Puntos: Observados (binarios) | L√≠neas: Modelos ajustados"
  ) +
  scale_y_continuous(limits = c(-0.1, 1.1)) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold")) +
  scale_color_manual(
    name = "Modelo",
    values = c("MPL" = "blue", "Probit" = "lightblue", "Logit" = "salmon")
  ) +
  guides(color = guide_legend(override.aes = list(linetype = c(2, 1, 1)))) +
  annotate("text", x = 2, y = 0.9, label = "MPL (azul, punteado)") +
  annotate("text", x = 2, y = 0.8, label = "Probit (light blue)") +
  annotate("text", x = 2, y = 0.7, label = "Logit (salmon)")

```

#### Secci√≥n 1: Modelos de respuesta binaria (Conclusiones generales) {.smaller}

**¬øCu√°l modelo elegir para variable binaria?**

| Criterio                           | MPL                                 | Logit                              | Probit                                        |
|-----------------|-----------------|-----------------|---------------------|
| **Facilidad de estimaci√≥n**        | ‚úÖ Muy f√°cil (OLS)                  | ‚ö†Ô∏è Requiere MLE                    | ‚ö†Ô∏è Requiere MLE                               |
| **Probabilidades v√°lidas \[0,1\]** | ‚ùå Puede salirse de rango           | ‚úÖ Siempre en \[0,1\]              | ‚úÖ Siempre en \[0,1\]                         |
| **Interpretaci√≥n directa**         | ‚úÖ Coef. son cambios en prob.       | ‚ö†Ô∏è Coef. en log-odds               | ‚ö†Ô∏è Coef. en unidad normal                     |
| **Robustez estad√≠stica**           | ‚ùå Problemas con heterocedasticidad | ‚úÖ M√°s robusto                     | ‚úÖ M√°s robusto                                |
| **Velocidad de c√°lculo**           | ‚úÖ Muy r√°pida                       | ‚úÖ R√°pido con paquetes optimizados | ‚ö†Ô∏è M√°s lento                                  |
| **Tradici√≥n en econom√≠a**          | üü° Preliminar o por simplicidad     | ‚úÖ Muy com√∫n                       | ‚úÖ Usado especialmente con variables latentes |
| **Interpretaci√≥n de odds ratio**   | ‚ùå No aplica                        | ‚úÖ S√≠, odds y odds ratio           | ‚ùå Menos intuitiva                            |
| **Predicci√≥n razonable**           | ‚ùå A veces no                       | ‚úÖ S√≠                              | ‚úÖ S√≠                                         |

#### Secci√≥n 1: Modelos de respuesta binaria (Conclusiones generales) {.smaller}

-   Usar **MPL** solo para exploraci√≥n inicial.
-   **Logit** si quieres interpretar en t√©rminos de **odds**.
-   Usar **Probit** si el error se supone **normal** o si hay variable latente subyacente.
